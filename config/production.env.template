# WhatsApp RAG (ES) - Production Environment Configuration Template
# Copy this file to .env and customize for your deployment

# ==============================================
# REQUIRED: GitHub Models API Configuration
# ==============================================

# GitHub Personal Access Token with GitHub Models access
# Generate at: https://github.com/settings/tokens
GITHUB_TOKEN=ghp_your_github_personal_access_token_here

# GitHub Models API endpoint (usually no need to change)
GH_MODELS_BASE_URL=https://models.github.ai/inference

# ==============================================
# LLM and Embedding Model Configuration  
# ==============================================

# Chat completion model for answering questions
# Options: openai/gpt-4o, openai/gpt-4o-mini, openai/gpt-3.5-turbo
CHAT_MODEL=openai/gpt-4o

# Remote embedding model for semantic search
# Options: openai/text-embedding-3-small, openai/text-embedding-3-large
EMBEDDING_MODEL=openai/text-embedding-3-small

# ==============================================
# Embedding Provider Configuration
# ==============================================

# Force use of local embeddings (0=remote preferred, 1=local only)
# Set to 1 for privacy-focused deployments or when API access is limited
USE_LOCAL_EMBEDDINGS=0

# Local embedding model (fallback when remote fails or USE_LOCAL_EMBEDDINGS=1)
# intfloat/multilingual-e5-small is optimized for Spanish content
LOCAL_EMBEDDING_MODEL=intfloat/multilingual-e5-small

# ==============================================
# Performance and Rate Limiting
# ==============================================

# Maximum number of texts to send per embedding API request
# Increase for better throughput, decrease if hitting rate limits
EMBED_BATCH_SIZE=64

# Maximum total characters per embedding API request
# Helps avoid 413 Payload Too Large errors
EMBED_MAX_CHARS_PER_REQUEST=60000

# Maximum characters per individual text (longer texts are truncated)
EMBED_MAX_CHARS_PER_ITEM=4000

# ==============================================
# Server Configuration
# ==============================================

# Server bind address
# 127.0.0.1 = localhost only
# 0.0.0.0 = accept connections from any IP (use with reverse proxy)
HOST=0.0.0.0

# Server port
PORT=7860

# Enable Gradio public sharing (0=no, 1=yes)
# WARNING: Only enable for development/testing, not production
GRADIO_SHARE=0

# Disable Gradio usage analytics
GRADIO_ANALYTICS_ENABLED=0

# ==============================================
# Logging Configuration
# ==============================================

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ==============================================
# Optional: Advanced Configuration
# ==============================================

# Custom logging format (uncomment to override default)
# LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Timeout for API requests (seconds)
# API_TIMEOUT=60

# Maximum file size for uploads (bytes)
# MAX_FILE_SIZE=50000000

# Enable CORS (for API access from web browsers)
# GRADIO_CORS_ALLOW_ORIGINS=*