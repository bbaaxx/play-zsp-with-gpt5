"""
Analysis and agent-based trend detection functionality.
"""

from __future__ import annotations

import os
import logging
from typing import Optional
from dataclasses import dataclass

from rag import ChatDataFrame, ChatAnalyzer, AnalysisResult, AdaptiveAnalyzer, AdaptiveAnalysisResult

logger = logging.getLogger(__name__)


@dataclass
class AnalysisConfig:
    """Configuration for analysis operations."""
    github_token: Optional[str] = None
    model_name: Optional[str] = None
    
    def __post_init__(self):
        if self.github_token is None:
            self.github_token = os.environ.get("GITHUB_TOKEN")
        if self.model_name is None:
            self.model_name = os.environ.get("CHAT_MODEL", "gpt-4o-mini")


class AnalyticsEngine:
    """Handles analysis and agent-based trend detection functionality."""
    
    def __init__(self, config: Optional[AnalysisConfig] = None):
        """Initialize analytics engine with configuration."""
        self.config = config or AnalysisConfig()
        self.last_analysis: Optional[AnalysisResult] = None
        self.last_adaptive_analysis: Optional[AdaptiveAnalysisResult] = None
    
    def _validate_configuration(self) -> Optional[str]:
        """Validate that required configuration is present."""
        if not self.config.github_token:
            return (
                "âŒ **Error de configuraciÃ³n**\n\n"
                "Para usar el anÃ¡lisis inteligente, necesitas configurar tu token de GitHub:\n\n"
                "1. Crea un archivo `.env` en la raÃ­z del proyecto\n"
                "2. Agrega la lÃ­nea: `GITHUB_TOKEN=tu_token_aquÃ­`\n"
                "3. ObtÃ©n tu token en: https://github.com/settings/tokens\n\n"
                "El token necesita acceso a GitHub Models para funcionar."
            )
        return None
    
    def _format_basic_analysis_results(self, result: AnalysisResult) -> str:
        """Format basic analysis results for display."""
        output = ["=== ANÃLISIS INTELIGENTE DE CONVERSACIÃ“N ===\n"]
        
        # Tendencias identificadas
        if result.trend_summaries:
            output.append("ğŸ” **TENDENCIAS Y PATRONES:**")
            for i, trend in enumerate(result.trend_summaries, 1):
                output.append(f"\n{i}. **{trend.trend_type.upper()}** (confianza: {trend.confidence_score:.1%})")
                output.append(f"   {trend.description}")
                if trend.time_period:
                    output.append(f"   PerÃ­odo: {trend.time_period}")
                if trend.participants:
                    output.append(f"   Participantes: {', '.join(trend.participants)}")
        else:
            output.append("ğŸ” **TENDENCIAS Y PATRONES:** No se detectaron patrones significativos.")
        
        # AnomalÃ­as detectadas
        output.append("\nâš ï¸ **COMPORTAMIENTOS INUSUALES:**")
        if result.anomalies:
            for i, anomaly in enumerate(result.anomalies, 1):
                severity_icon = "ğŸŸ¥" if anomaly.severity == "high" else "ğŸŸ¨" if anomaly.severity == "medium" else "ğŸŸ©"
                output.append(f"\n{i}. {severity_icon} **{anomaly.anomaly_type.upper()}**")
                output.append(f"   {anomaly.description}")
                if anomaly.participant:
                    output.append(f"   Participante: {anomaly.participant}")
        else:
            output.append("No se detectaron comportamientos inusuales.")
        
        # Mensajes memorables
        output.append("\nğŸ’¬ **MENSAJES MEMORABLES:**")
        if result.quotable_messages:
            for i, quote in enumerate(result.quotable_messages, 1):
                type_icon = "ğŸ˜‚" if quote.quote_type == "funny" else "ğŸ’­" if quote.quote_type == "insightful" else "â¤ï¸" if quote.quote_type == "emotional" else "â­"
                output.append(f"\n{i}. {type_icon} **{quote.sender}** ({quote.timestamp.strftime('%Y-%m-%d %H:%M')})")
                output.append(f"   \"{quote.message}\"")
                output.append(f"   Relevancia: {quote.relevance_score:.1%} | Tipo: {quote.quote_type}")
                if quote.context:
                    output.append(f"   Contexto: {quote.context}")
        else:
            output.append("No se encontraron mensajes especialmente memorables.")
        
        # Metadatos
        output.append("\nğŸ“Š **METADATOS DEL ANÃLISIS:**")
        output.append(f"- Mensajes analizados: {result.analysis_metadata.get('total_messages_analyzed', 0)}")
        output.append(f"- Modelo usado: {result.analysis_metadata.get('model_used', 'N/A')}")
        output.append(f"- AnÃ¡lisis realizado: {result.analysis_metadata.get('analysis_timestamp', 'N/A')}")
        
        return "\n".join(output)
    
    def _format_adaptive_analysis_results(self, result: AdaptiveAnalysisResult) -> str:
        """Format adaptive analysis results for display."""
        output = ["=== ANÃLISIS ADAPTATIVO DE DOS ETAPAS ===\n"]
        
        # Contextos detectados
        output.append("ğŸ¯ **CONTEXTOS DETECTADOS:**")
        if result.detected_contexts:
            for i, context in enumerate(result.detected_contexts, 1):
                confidence_text = "ğŸŸ¢ Alta" if context.confidence > 0.7 else "ğŸŸ¡ Media" if context.confidence > 0.4 else "ğŸ”´ Baja"
                output.append(f"\n{i}. **{context.category.replace('_', ' ').title()}** - {confidence_text} ({context.confidence:.1%})")
                if context.evidence:
                    output.append(f"   ğŸ“‹ Evidencia:")
                    for evidence_item in context.evidence:
                        output.append(f"     â€¢ {evidence_item}")
        else:
            output.append("No se detectaron contextos especÃ­ficos.")
        
        # AnÃ¡lisis especializados
        output.append("\nğŸ”¬ **ANÃLISIS ESPECIALIZADOS:**")
        if result.specialized_analyses:
            for context_type, analyses in result.specialized_analyses.items():
                context_name = context_type.replace('_', ' ').title()
                output.append(f"\nğŸ“Š **{context_name}:**")
                
                if isinstance(analyses, dict) and "error" not in analyses:
                    for focus_area, analysis in analyses.items():
                        if analysis and isinstance(analysis, str):
                            area_name = focus_area.replace('_', ' ').title()
                            # Show complete analysis without truncation
                            output.append(f"   â€¢ **{area_name}**:")
                            # Format the analysis with proper indentation
                            analysis_lines = analysis.strip().split('\n')
                            for line in analysis_lines:
                                if line.strip():
                                    output.append(f"     {line}")
                            output.append("")  # Add blank line for readability
                elif "error" in analyses:
                    output.append(f"   âš ï¸ Error en anÃ¡lisis: {analyses['error']}")
        else:
            output.append("No se generaron anÃ¡lisis especializados.")
        
        # Insights adaptativos
        output.append("\nğŸ’¡ **INSIGHTS ADAPTATIVOS:**")
        if result.adaptive_insights:
            for insight in result.adaptive_insights:
                output.append(f"\n{insight}")
        else:
            output.append("No se generaron insights adaptativos.")
        
        # AnÃ¡lisis bÃ¡sico (resumen)
        basic = result.basic_analysis
        output.append("\nğŸ“ˆ **RESUMEN ANÃLISIS BÃSICO:**")
        output.append(f"â€¢ {len(basic.trend_summaries)} tendencias identificadas")
        output.append(f"â€¢ {len(basic.anomalies)} anomalÃ­as detectadas")
        output.append(f"â€¢ {len(basic.quotable_messages)} mensajes memorables")
        
        # Metadatos
        output.append("\nğŸ“Š **METADATOS:**")
        output.append(f"- Contextos detectados: {result.analysis_metadata.get('total_contexts_detected', 0)}")
        output.append(f"- Agentes especializados: {result.analysis_metadata.get('specialized_agents_used', 0)}")
        output.append(f"- VersiÃ³n anÃ¡lisis: {result.analysis_metadata.get('analysis_version', 'N/A')}")
        output.append(f"- Realizado: {result.analysis_metadata.get('analysis_timestamp', 'N/A')[:19]}")
        
        return "\n".join(output)
    
    def analyze_chat_basic(self, chat_dataframe: ChatDataFrame, progress_callback=None) -> str:
        """Perform basic intelligent chat analysis using smolagents."""
        if progress_callback is not None:
            progress_callback(0, desc="Iniciando anÃ¡lisis...")
        
        if chat_dataframe is None or chat_dataframe.is_empty:
            return "No hay datos de chat cargados para analizar. Primero indexa un archivo."
        
        if progress_callback is not None:
            progress_callback(0.1, desc="Verificando configuraciÃ³n...")
        
        # Check configuration
        config_error = self._validate_configuration()
        if config_error:
            return config_error
        
        try:
            if progress_callback is not None:
                progress_callback(0.2, desc="Configurando analizador...")
            
            # Create analyzer
            analyzer = ChatAnalyzer(llm_model_name=self.config.model_name)
            
            if progress_callback is not None:
                progress_callback(0.3, desc="Ejecutando anÃ¡lisis inteligente... (esto puede tomar algunos minutos)")
            
            # Perform full analysis
            result = analyzer.full_analysis(chat_dataframe)
            self.last_analysis = result
            
            if progress_callback is not None:
                progress_callback(0.8, desc="Procesando resultados...")
                progress_callback(0.9, desc="Formateando resultados...")
            
            formatted_results = self._format_basic_analysis_results(result)
            
            if progress_callback is not None:
                progress_callback(1.0, desc="âœ… AnÃ¡lisis completado")
            
            return formatted_results
            
        except Exception as e:
            logger.exception("Error durante el anÃ¡lisis inteligente")
            return f"Error durante el anÃ¡lisis: {e}\n\nVerifica que tengas configurado correctamente el acceso a modelos LLM (variables de entorno GITHUB_TOKEN, etc.)"
    
    def analyze_chat_adaptive(self, chat_dataframe: ChatDataFrame, progress_callback=None) -> str:
        """Perform adaptive two-stage analysis."""
        if progress_callback is not None:
            progress_callback(0, desc="Iniciando anÃ¡lisis adaptativo...")
        
        if chat_dataframe is None or chat_dataframe.is_empty:
            return "No hay datos de chat cargados para analizar. Primero indexa un archivo."
        
        if progress_callback is not None:
            progress_callback(0.1, desc="Verificando configuraciÃ³n...")
        
        # Check configuration
        config_error = self._validate_configuration()
        if config_error:
            return config_error.replace("anÃ¡lisis inteligente", "anÃ¡lisis adaptativo")
        
        try:
            if progress_callback is not None:
                progress_callback(0.2, desc="Configurando analizador adaptativo...")
            
            # Create adaptive analyzer
            adaptive_analyzer = AdaptiveAnalyzer()
            
            if progress_callback is not None:
                progress_callback(0.3, desc="Etapa 1: Ejecutando anÃ¡lisis bÃ¡sico...")
                progress_callback(0.5, desc="Etapa 2: Detectando contextos de conversaciÃ³n...")
                progress_callback(0.7, desc="Etapa 3: Creando agentes especializados...")
                progress_callback(0.85, desc="Etapa 4: Ejecutando anÃ¡lisis especializados...")
            
            # Perform full adaptive analysis
            result = adaptive_analyzer.analyze(chat_dataframe)
            self.last_adaptive_analysis = result
            
            if progress_callback is not None:
                progress_callback(0.95, desc="Formateando resultados...")
            
            formatted_results = self._format_adaptive_analysis_results(result)
            
            if progress_callback is not None:
                progress_callback(1.0, desc="âœ… AnÃ¡lisis adaptativo completado")
            
            return formatted_results
            
        except Exception as e:
            logger.exception("Error durante el anÃ¡lisis adaptativo")
            return f"Error durante el anÃ¡lisis adaptativo: {e}\n\nVerifica que tengas configurado correctamente el acceso a modelos LLM."
    
    def get_analysis_summary(self) -> str:
        """Get a quick summary of the last analyses."""
        if self.last_analysis is None and self.last_adaptive_analysis is None:
            return "No hay anÃ¡lisis previo disponible."
        
        summary = ["ğŸ“Š **Ãšltimos AnÃ¡lisis:**"]
        
        # Basic analysis summary
        if self.last_analysis is not None:
            result = self.last_analysis
            summary.extend([
                "\nğŸ” **AnÃ¡lisis BÃ¡sico:**",
                f"â€¢ {len(result.trend_summaries)} tendencias identificadas",
                f"â€¢ {len(result.anomalies)} anomalÃ­as detectadas", 
                f"â€¢ {len(result.quotable_messages)} mensajes memorables",
                f"â€¢ Realizado: {result.analysis_metadata.get('analysis_timestamp', 'N/A')[:19]}"
            ])
        
        # Adaptive analysis summary
        if self.last_adaptive_analysis is not None:
            result = self.last_adaptive_analysis
            summary.extend([
                "\nğŸ¯ **AnÃ¡lisis Adaptativo:**",
                f"â€¢ {len(result.detected_contexts)} contextos detectados",
                f"â€¢ {result.analysis_metadata.get('specialized_agents_used', 0)} agentes especializados",
                f"â€¢ {len(result.adaptive_insights)} insights adaptativos",
                f"â€¢ Realizado: {result.analysis_metadata.get('analysis_timestamp', 'N/A')[:19]}"
            ])
        
        return "\n".join(summary)
    
    def clear_analysis_state(self):
        """Clear analysis state."""
        self.last_analysis = None
        self.last_adaptive_analysis = None
        logger.info("Estado de anÃ¡lisis limpiado")